model_name      : "models/qwen2.5_3B"
dataset_name    : "lvwerra/stack-exchange-paired"
subset          : "data/finetune"
split           : "train"
size_valid_set  : 4000
streaming       : False
shuffle_buffer  : 5000
seq_length      : 1024
num_workers     : 1
use_bnb         : True
seed            : 2025
max_steps       : 2000
hf_token        : ""



r              : 8
lora_alpha     : 16
lora_dropout   : 0.05
target_modules : ["q_proj", "v_proj"]
bias           : "none"
task_type      : "CAUSAL_LM"


output_dir                  : "./sft_model_output"
per_device_train_batch_size : 4
per_device_eval_batch_size  : 4 
learning_rate               : 0.00002         
num_train_epochs            : 4       
max_seq_length              : 1024
dataset_text_field          : "text"
gradient_accumulation_steps : 4
bf16                        : True
fp16                        : False
gradient_checkpointing      : True
report_to                   : "mlflow"
logging_steps               : 10
